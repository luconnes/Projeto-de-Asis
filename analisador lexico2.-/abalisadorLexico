import ply.lex as lex

# Lista de tokens
tokens = [
    'PALAVRA_CHAVE',
    'OPERADOR',
    'SIMBOLO',
    'IDENTIFICADOR',
    'NUMERO_DECIMAL',
    'NUMERO_INTEIRO',
    'STRING',
    'CHARACTER',
    'COMENTARIO',
]

# Expressões regulares para tokens simples
t_ignore = ' \t'

t_PALAVRA_CHAVE = r'\b(int|float|double|char|boolean|void|def|input|if|else|while|for|' \
                  r'switch|case|default|break|continue|return|struct|println|main)\b'

t_OPERADOR = r'\+\+|--|<=|>=|==|!=|&&|\|\||=|<|>|\+|-|\*|/|%'

t_SIMBOLO = r'[\(\)\[\]\{\},;.]'

# Funções para tokens complexos
def t_NUMERO_DECIMAL(t):
    r'\b\d+\.\d+\b'
    t.value = float(t.value)
    return t

def t_NUMERO_INTEIRO(t):
    r'\b\d+\b'
    t.value = int(t.value)
    return t

def t_STRING(t):
    r'"([^"\\]*(\\.[^"\\]*)*)"'
    t.value = t.value[1:-1]  # Remove as aspas
    return t

def t_CHARACTER(t):
    r"'.'"
    t.value = t.value[1:-1]  # Remove as aspas
    return t

def t_IDENTIFICADOR(t):
    r'[a-zA-Z_][a-zA-Z0-9_]*'
    return t

def t_COMENTARIO(t):
    r'/\*([^*]|[\r\n]|(\*+([^*/]|[\r\n])))*\*+/'
    t.lexer.lineno += t.value.count('\n')
    pass  # Ignorar comentários de bloco

def t_COMENTARIO_LINHA(t):
    r'//.*'
    pass  # Ignorar comentários de linha

def t_newline(t):
    r'\n+'
    t.lexer.lineno += t.value.count("\n")

def t_error(t):
    print(f"Caractere inválido: {t.value[0]}")
    t.lexer.skip(1)

# Criar analisador léxico
lexer = lex.lex()

# Teste
if __name__ == "__main__":
    with open("input.txt", "r") as file:
        lexer.input(file.read())

    for token in lexer:
        print(token)
